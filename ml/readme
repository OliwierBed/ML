# ğŸ“ ML Module Overview

Ten katalog `ml/` odpowiada za caÅ‚y proces uczenia i predykcji modeli ML (aktualnie LSTM z uwzglÄ™dnieniem attention). MoÅ¼e byÄ‡ Å‚atwo rozszerzony o dodatkowe cechy wejÅ›ciowe i inne typy modeli.

---

## ğŸ“‚ Struktura katalogu

ml/
â”œâ”€â”€ inference/
â”‚ â””â”€â”€ service.py # ObsÅ‚uga predykcji z pliku modelu (.pth)
â”œâ”€â”€ models/
â”‚ â””â”€â”€ lstm_attention.py # Architektura LSTM z Attention
â”œâ”€â”€ saved_models/
â”‚ â””â”€â”€ lstm_TICKER_INTERVAL.pth # Zapisane modele
â”‚ â””â”€â”€ lstm_TICKER_INTERVAL.meta.json # Metadane modelu (cechy, seq_len)
â”‚ â””â”€â”€ lstm_TICKER_INTERVAL.scaler.pkl # Zapisany scaler MinMax
â”œâ”€â”€ training/
â”‚ â””â”€â”€ train_lstm.py # Trening modelu LSTM
â””â”€â”€ README_ml.md # Ten plik

## ğŸ§  DziaÅ‚anie systemu

### 1. Trening (`train_lstm.py`)
- Trenuje model LSTM na danych z `data-pipelines/feature_stores/data/raw/{ticker}_{interval}_*.csv`.
- Dane `close` sÄ… normalizowane (domyÅ›lnie), ale moÅ¼na rozszerzyÄ‡ o inne kolumny.
- Zapisuje:
  - `.pth` â€“ model,
  - `.scaler.pkl` â€“ obiekt skalujÄ…cy (do uÅ¼ycia przy predykcji),
  - `.meta.json` â€“ metadane (lista cech, dÅ‚ugoÅ›Ä‡ sekwencji itp.).

### 2. Predykcja (`service.py`)
- Åaduje najnowszy model `.pth` + `.scaler.pkl` + `.meta.json` z `saved_models/`.
- Pobiera dane z katalogu `raw/`, wycina ostatnie `seq_len` wartoÅ›ci i generuje prognozÄ™.

---

## ğŸ§© ObsÅ‚uga wielu cech (features)

DomyÅ›lnie model dziaÅ‚a tylko na `close`. Aby dodaÄ‡ inne cechy:

1. Zmodyfikuj `train_lstm.py`:
   - Podaj `features = ["close", "open", "rsi_14", "sma_20", ...]`
   - Skaluj wszystkie cechy razem: `scaler.fit_transform(df[features])`
   - `X` ma wymiar: `[n, seq_len, num_features]`

2. Zmodyfikuj `service.py`:
   - Wczytaj te same `features` z `.meta.json`
   - Przeskaluj dane tym samym `scaler.pkl`

âœ… Frontend i API NIE wymagajÄ… Å¼adnych zmian.

---

## ğŸ§ª ML Developer: Twoje zadania

1. **Dodawanie cech**:
   - Analiza danych (np. korelacja, jakoÅ›Ä‡, noise),
   - Dodanie np. RSI, SMA, OBV, MACD, Stoch, itd.

2. **Optymalizacja**:
   - DobÃ³r `seq_len`, `epochs`, `hidden_dim`, dropout, LR,
   - Zapobieganie overfittingowi (np. przez walidacjÄ™, wykresy loss).

3. **Walidacja**:
   - PorÃ³wnaj przewidywane wartoÅ›ci z rzeczywistymi (`MAE`, `MSE`, `RMSE`),
   - MoÅ¼esz stworzyÄ‡ wykresy porÃ³wnawcze.

4. **ModularnoÅ›Ä‡**:
   - ObsÅ‚uga wielu modeli (np. GRU, CNN-LSTM),
   - UÅ¼ywaj `meta.json` i `scaler.pkl`, by trenowaÄ‡ i przewidywaÄ‡ dowolnym zestawem cech.

---

## âš™ï¸ SkalowalnoÅ›Ä‡

- Frontend i backend API **automatycznie** korzystajÄ… z najnowszego modelu `.pth` + `.scaler.pkl` + `.meta.json`.
- MoÅ¼na Å‚atwo trenowaÄ‡ i przewidywaÄ‡ dowolny `ticker` + `interval`.
- Wystarczy umieÅ›ciÄ‡ dane w `data/raw/` i wszystko dziaÅ‚a.

---

## ğŸ“¦ Wymagania

- PyTorch
- Pandas, NumPy, scikit-learn
- FastAPI
- Streamlit (frontend)

---

## ğŸ§­ PrzykÅ‚adowe wywoÅ‚ania

### Trening z CLI:
```bash
python -m ml.training.train_lstm --ticker AAPL --interval 1d --epochs 30



Trening z API:
POST /ml/train?ticker=AAPL&interval=1d&epochs=30

Predykcja:
GET /ml/forecast?ticker=AAPL&interval=1d&n_steps=100
